{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(boston.data,columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(boston.target, columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711226005748496"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8749965273218174"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вторая модель лучше, т.к. r^2 ближе к еденице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999994"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fee42335e48>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(importance, index=X.columns)\n",
    "feat_importances.sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 30) (85443, 30) (199364,) (85443,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'n_estimators': [10, 15], \n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator=RandomForestClassifier(random_state=100), \n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=100, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [10, 15], 'max_features': array([3, 4]), 'max_depth': array([4, 5, 6])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630902415719197"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, y_pred_proba) # почему-то когда подсталвяю y_test, получаю ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
